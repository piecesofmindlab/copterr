{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to Alternative Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "np.random.seed(0)\n",
    "\n",
    "def create_fake_data(n_timepoints_train, n_timepoints_test, n_features, n_targets, noise_amounts):\n",
    "    # Create features\n",
    "    X_train = np.random.rand(n_timepoints_train, n_features)\n",
    "    X_test = np.random.rand(n_timepoints_test, n_features)\n",
    "    true_weights = np.random.randn(n_features, n_targets)\n",
    "\n",
    "    # Create targets\n",
    "    Y_train = X_train @ true_weights\n",
    "    Y_test = X_test @ true_weights\n",
    "\n",
    "    # Add different amounts of noise\n",
    "    for target_i in range(n_targets):\n",
    "        Y_train[:,target_i] += noise_amounts[target_i]  * np.random.randn(n_timepoints_train)\n",
    "        Y_test[:,target_i] += noise_amounts[target_i] * np.random.randn(n_timepoints_test)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "n_timepoints_train, n_timepoints_test = 500, 100\n",
    "n_features, n_targets = 10, 3\n",
    "noise_amounts = [1,5,15]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_fake_data(\n",
    "    n_timepoints_train=n_timepoints_train,\n",
    "    n_timepoints_test=n_timepoints_test,\n",
    "    n_features=n_features,\n",
    "    n_targets=n_targets,\n",
    "    noise_amounts=noise_amounts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the example notebook, we'll compute our main regression fit using Himalaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score Per Target:  [ 0.50214792  0.0137505  -0.0056149 ]\n"
     ]
    }
   ],
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "\n",
    "model = RidgeCV(alphas=np.logspace(-2, 5, 8))\n",
    "model.fit(X_train, Y_train)\n",
    "himalaya_scores = model.score(X_test, Y_test)\n",
    "print(\"R2 Score Per Target: \", himalaya_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll compute p value for R2 of each of our targets using COPTeRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Initial SVDs: 100%|██████████| 3/3 [00:00<00:00, 2600.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Equivalent: True\n",
      "R2 Scores Equivalent: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from copterr import PermuteWeights\n",
    "\n",
    "permuter = PermuteWeights(X_train, Y_train, model.best_alphas_)\n",
    "permuter.prepare()\n",
    "\n",
    "himalaya_weights = model.coef_\n",
    "copterr_weights = permuter.fit_true_weights()\n",
    "print('Weights Equivalent:', np.allclose(himalaya_weights, copterr_weights, atol=1e-5))\n",
    "\n",
    "copterr_scores = permuter.score(X_test, Y_test).numpy()\n",
    "print('R2 Scores Equivalent:', np.allclose(himalaya_scores, copterr_scores, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute with copterr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f8f4b027184f47b0047edb02d1606a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 R2: 0.502      P-Value: 0.00\n",
      "Target 1 R2: 0.014      P-Value: 0.01\n",
      "Target 2 R2: -0.006      P-Value: 0.11\n"
     ]
    }
   ],
   "source": [
    "from copterr.utils import compute_p_values\n",
    "\n",
    "perm_performance = []\n",
    "for permutation in tqdm(range(10000)):\n",
    "    perm_weights = permuter.fit_permutation(permutation=True)\n",
    "    perm_r2 = permuter.score(X_test, Y_test, permutation=True)\n",
    "    perm_performance.append(perm_r2.numpy())\n",
    "\n",
    "p_values = compute_p_values(copterr_scores, perm_performance)\n",
    "\n",
    "for target_i in range(n_targets):\n",
    "    print(f\"Target {target_i} R2:\", \"%0.3f\" % copterr_scores[target_i], \"    \", \"P-Value:\", \"%0.2f\" % p_values[target_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to estimate significance for regression models is by shuffling the input features, and then fully re-estimating the regression weights. We'll test this by repeatedly shuffling and fitting using Himalaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca97caf6275b4476841301027a2c2e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from himalaya.ridge import Ridge\n",
    "from copterr.utils import compute_p_values\n",
    "\n",
    "permutation_model = Ridge(alpha=model.best_alphas_)\n",
    "X_train_shuffled = X_train.copy()\n",
    "X_test_shuffled = X_test.copy()\n",
    "\n",
    "perm_performance = []\n",
    "for i in tqdm(range(10000)):\n",
    "    np.random.shuffle(X_train_shuffled)\n",
    "    np.random.shuffle(X_test_shuffled)\n",
    "    permutation_model.fit(X_train_shuffled, Y_train)\n",
    "    perm_r2 = permutation_model.score(X_test_shuffled, Y_test)\n",
    "    perm_performance.append(perm_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 R2: 0.502      P-Value: 0.00\n",
      "Target 1 R2: 0.014      P-Value: 0.01\n",
      "Target 2 R2: -0.006      P-Value: 0.11\n"
     ]
    }
   ],
   "source": [
    "p_values = compute_p_values(himalaya_scores, perm_performance)\n",
    "\n",
    "for target_i in range(n_targets):\n",
    "    print(f\"Target {target_i} R2:\", \"%0.3f\" % himalaya_scores[target_i], \"    \", \"P-Value:\", \"%0.2f\" % p_values[target_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can do it the copterr way, but without copterr optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a8abb7035145c9b4370546d38e5306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from himalaya.ridge import Ridge\n",
    "from copterr.utils import compute_p_values\n",
    "\n",
    "permutation_model = Ridge(alpha=model.best_alphas_)\n",
    "Y_train_shuffled = Y_train.copy()\n",
    "Y_test_shuffled = Y_test.copy()\n",
    "\n",
    "perm_performance = []\n",
    "for i in tqdm(range(10000)):\n",
    "    np.random.shuffle(Y_train_shuffled)\n",
    "    np.random.shuffle(Y_test_shuffled)\n",
    "    permutation_model.fit(X_train, Y_train_shuffled)\n",
    "    perm_r2 = permutation_model.score(X_test, Y_test_shuffled)\n",
    "    perm_performance.append(perm_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 R2: 0.502      P-Value: 0.00\n",
      "Target 1 R2: 0.014      P-Value: 0.01\n",
      "Target 2 R2: -0.006      P-Value: 0.11\n"
     ]
    }
   ],
   "source": [
    "p_values = compute_p_values(himalaya_scores, perm_performance)\n",
    "\n",
    "for target_i in range(n_targets):\n",
    "    print(f\"Target {target_i} R2:\", \"%0.3f\" % himalaya_scores[target_i], \"    \", \"P-Value:\", \"%0.2f\" % p_values[target_i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pomlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
